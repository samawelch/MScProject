filter_(temp_filter)
# filter_() is technically deprecated; however I am practically unable to understand quasiquotation though, so here it stays
# an elegant function for a more civilized age
# At some point when we're done we'll need to empty this vector again
temp_filter_vector[1:8] <- ""
# We can now calculate a pred_comp_mean from the divided sum of our component obs_means, likewise for n and sd
temp_ho_emergent_interaction_tibble$pred_comp_mean[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_mean = (sum(obs_mean)/nrow(component_emergent_filtered_interaction_tibble))))
# I believe here the standard deviation should be the equal to the square root of the sum of (the squared component SDs) divided by the number of component combinations
temp_ho_emergent_interaction_tibble$pred_comp_sd[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_sd = sqrt(sum((obs_mean ^ 2)))/nrow(component_emergent_filtered_interaction_tibble)))
# And our new sample size is summed, divided by the number of component combinations, and rounded to the nearest whole number
temp_ho_emergent_interaction_tibble$pred_comp_n[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_n = round(sum(obs_n) / nrow(component_emergent_filtered_interaction_tibble))))
# And append to emergent_interactions_tibble_app
emergent_interactions_tibble_app <- bind_rows(emergent_interactions_tibble_app, temp_ho_emergent_interaction_tibble[r,])
# And now we're gonna T-test observed effect vs component predicted effect
# I really need to come up with better names for these things.
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
# If m1 > m2, then additive_test[1] > 0
additive_test <- t.test2(emergent_interactions_tibble_app$pred_comp_mean[r], emergent_interactions_tibble_app$obs_mean[r],
emergent_interactions_tibble_app$pred_comp_sd[r], emergent_interactions_tibble_app$obs_sd[r],
emergent_interactions_tibble_app$pred_comp_n[r], emergent_interactions_tibble_app$obs_n[r])
# We also need to catch NaNs and NAs
# We'll just use simple definitions of synergy and antagonism here.
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
emergent_interactions_tibble_app$pred_comp_interaction[r] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
emergent_interactions_tibble_app$pred_comp_interaction[r] <- "Predicted"
} else if (additive_test[3] > 0)
{
emergent_interactions_tibble_app$pred_comp_interaction[r] <- "Emergent Synergy"
} else if (additive_test[3] < 0)
{
emergent_interactions_tibble_app$pred_comp_interaction[r] <- "Emergent Antagonism"
} else
{
emergent_interactions_tibble_app$pred_comp_interaction[r] <- "Classification Error"
}
}
}
}
emergent_interactions_tibble_app$pred_comp_interaction[r]
r
temp_ho_emergent_interaction_tibble
# A test for emergent interactions, using Beppler's measurement of bacterial fitness to predict complex interactions from component interactions
# The magnum opus of my 'throw a lot of for loops at a wall and see what sticks' approach to programming in R
library(dplyr)
library(rlang)
setwd(here("Scripts"))
# We essentially want to run Define_Interaction.R, but rather than simply using single stressor effects to predict growth
# We want to use the sum of all (component effects at (richness - 1) divided by richness)
# I'm not planning to use all component levels of richness to try and predict interactions, because life's too short
# Set your p-cutoff for additivism here
p_cutoff <- 0.05
# We'll need this vector for filtering component combinations later
temp_filter_vector <- vector(length = 8, mode = "character")
# Calculate the effect of individual stressors relative to controls, by isolate
emergent_interactions_tibble <- all_interactions_tibble %>%
mutate(pred_comp_mean = 0, pred_comp_sd = 0, pred_comp_n = 0, pred_comp_interaction = "")
# This is ugly.
emergent_interactions_tibble_app <-
emergent_interactions_tibble[0,] %>%
mutate(pred_comp_interaction = "")
# By isolate
for (i in 1:8)
{
print(paste("i =", i))
for (o in 3:8)
{
print(paste("o =", o))
# For a given higher-order (n > 2) mixture, filter the tibble down
temp_ho_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o) %>% # in retrospect Richness == o is not very human-friendly
filter(Isolate == isolates_vector[i])
# Also generate a tibble of n-1 order interactions
temp_component_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o-1) %>%
filter(Isolate == isolates_vector[i])
# Now let's work out way through the combinations
for (r in 1:nrow(temp_ho_emergent_interaction_tibble))
{
# loop across stressor presence/absence data. append the names of any absent stressors to a vector we'll be using for filtering
for (q in 1:8)
{
if (temp_ho_emergent_interaction_tibble[r,q] == 1)
{
temp_filter_vector[q] <- colnames(temp_ho_emergent_interaction_tibble[q])
}
}
# Now that we've got a vector of all the stressors we care about, we can use it to filter the Richness == (n-1) dataset
# Remove empty elements
temp_filter_vector <- temp_filter_vector[temp_filter_vector != ""]
# paste paste paste
temp_filter <- paste("(", paste(paste("(", temp_filter_vector, " == 1", ")", sep = ""), collapse = " | "), ")", sep = "")
# And give it a stupid name
component_emergent_filtered_interaction_tibble <- temp_component_emergent_interaction_tibble %>%
filter_(temp_filter)
# filter_() is technically deprecated; however I am practically unable to understand quasiquotation though, so here it stays
# an elegant function for a more civilized age
# At some point when we're done we'll need to empty this vector again
temp_filter_vector[1:8] <- ""
# We can now calculate a pred_comp_mean from the divided sum of our component obs_means, likewise for n and sd
temp_ho_emergent_interaction_tibble$pred_comp_mean[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_mean = (sum(obs_mean)/nrow(component_emergent_filtered_interaction_tibble))))
# I believe here the standard deviation should be the equal to the square root of the sum of (the squared component SDs) divided by the number of component combinations
temp_ho_emergent_interaction_tibble$pred_comp_sd[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_sd = sqrt(sum((obs_mean ^ 2)))/nrow(component_emergent_filtered_interaction_tibble)))
# And our new sample size is summed, divided by the number of component combinations, and rounded to the nearest whole number
temp_ho_emergent_interaction_tibble$pred_comp_n[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_n = round(sum(obs_n) / nrow(component_emergent_filtered_interaction_tibble))))
# And now we're gonna T-test observed effect vs component predicted effect
# I really need to come up with better names for these things.
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
# If m1 > m2, then additive_test[1] > 0
additive_test <- t.test2(temp_ho_emergent_interaction_tibble$pred_comp_mean[r], temp_ho_emergent_interaction_tibble$obs_mean[r],
temp_ho_emergent_interaction_tibble$pred_comp_sd[r], temp_ho_emergent_interaction_tibble$obs_sd[r],
temp_ho_emergent_interaction_tibble$pred_comp_n[r], temp_ho_emergent_interaction_tibble$obs_n[r])
# We also need to catch NaNs and NAs
# We'll just use simple definitions of synergy and antagonism here.
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Predicted"
} else if (additive_test[3] > 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Synergy"
} else if (additive_test[3] < 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Antagonism"
} else
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Classification Error"
}
# And append to emergent_interactions_tibble_app
emergent_interactions_tibble_app <- bind_rows(emergent_interactions_tibble_app, temp_ho_emergent_interaction_tibble[r,])
}
}
}
warnings
warnings()
ggplot(data = emergent_interactions_tibble_app, aes(x = Isolate, fill = pred_comp_interaction)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
# A test for emergent interactions, using Beppler's measurement of bacterial fitness to predict complex interactions from component interactions
# The magnum opus of my 'throw a lot of for loops at a wall and see what sticks' approach to programming in R
library(dplyr)
library(rlang)
setwd(here("Scripts"))
# We essentially want to run Define_Interaction.R, but rather than simply using single stressor effects to predict growth
# We want to use the sum of all (component effects at (richness - 1) divided by richness)
# I'm not planning to use all component levels of richness to try and predict interactions, because life's too short
# Set your p-cutoff for additivism here
p_cutoff <- 0.5
# We'll need this vector for filtering component combinations later
temp_filter_vector <- vector(length = 8, mode = "character")
# Calculate the effect of individual stressors relative to controls, by isolate
emergent_interactions_tibble <- all_interactions_tibble %>%
mutate(pred_comp_mean = 0, pred_comp_sd = 0, pred_comp_n = 0, pred_comp_interaction = "")
# This is ugly.
emergent_interactions_tibble_app <-
emergent_interactions_tibble[0,] %>%
mutate(pred_comp_interaction = "")
# By isolate
for (i in 1:8)
{
print(paste("i =", i))
for (o in 3:8)
{
print(paste("o =", o))
# For a given higher-order (n > 2) mixture, filter the tibble down
temp_ho_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o) %>% # in retrospect Richness == o is not very human-friendly
filter(Isolate == isolates_vector[i])
# Also generate a tibble of n-1 order interactions
temp_component_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o-1) %>%
filter(Isolate == isolates_vector[i])
# Now let's work out way through the combinations
for (r in 1:nrow(temp_ho_emergent_interaction_tibble))
{
# loop across stressor presence/absence data. append the names of any absent stressors to a vector we'll be using for filtering
for (q in 1:8)
{
if (temp_ho_emergent_interaction_tibble[r,q] == 1)
{
temp_filter_vector[q] <- colnames(temp_ho_emergent_interaction_tibble[q])
}
}
# Now that we've got a vector of all the stressors we care about, we can use it to filter the Richness == (n-1) dataset
# Remove empty elements
temp_filter_vector <- temp_filter_vector[temp_filter_vector != ""]
# paste paste paste
temp_filter <- paste("(", paste(paste("(", temp_filter_vector, " == 1", ")", sep = ""), collapse = " | "), ")", sep = "")
# And give it a stupid name
component_emergent_filtered_interaction_tibble <- temp_component_emergent_interaction_tibble %>%
filter_(temp_filter)
# filter_() is technically deprecated; however I am practically unable to understand quasiquotation though, so here it stays
# an elegant function for a more civilized age
# At some point when we're done we'll need to empty this vector again
temp_filter_vector[1:8] <- ""
# We can now calculate a pred_comp_mean from the divided sum of our component obs_means, likewise for n and sd
temp_ho_emergent_interaction_tibble$pred_comp_mean[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_mean = (sum(obs_mean)/nrow(component_emergent_filtered_interaction_tibble))))
# I believe here the standard deviation should be the equal to the square root of the sum of (the squared component SDs) divided by the number of component combinations
temp_ho_emergent_interaction_tibble$pred_comp_sd[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_sd = sqrt(sum((obs_mean ^ 2)))/nrow(component_emergent_filtered_interaction_tibble)))
# And our new sample size is summed, divided by the number of component combinations, and rounded to the nearest whole number
temp_ho_emergent_interaction_tibble$pred_comp_n[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_n = round(sum(obs_n) / nrow(component_emergent_filtered_interaction_tibble))))
# And now we're gonna T-test observed effect vs component predicted effect
# I really need to come up with better names for these things.
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
# If m1 > m2, then additive_test[1] > 0
additive_test <- t.test2(temp_ho_emergent_interaction_tibble$pred_comp_mean[r], temp_ho_emergent_interaction_tibble$obs_mean[r],
temp_ho_emergent_interaction_tibble$pred_comp_sd[r], temp_ho_emergent_interaction_tibble$obs_sd[r],
temp_ho_emergent_interaction_tibble$pred_comp_n[r], temp_ho_emergent_interaction_tibble$obs_n[r])
# We also need to catch NaNs and NAs
# We'll just use simple definitions of synergy and antagonism here.
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Predicted"
} else if (additive_test[3] > 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Synergy"
} else if (additive_test[3] < 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Antagonism"
} else
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Classification Error"
}
# And append to emergent_interactions_tibble_app
emergent_interactions_tibble_app <- bind_rows(emergent_interactions_tibble_app, temp_ho_emergent_interaction_tibble[r,])
}
}
}
# Diagnostics.
ggplot(data = emergent_interactions_tibble_app, aes(x = Isolate, fill = pred_comp_interaction)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
View(emergent_interactions_tibble_app)
# A test for emergent interactions, using Beppler's measurement of bacterial fitness to predict complex interactions from component interactions
# The magnum opus of my 'throw a lot of for loops at a wall and see what sticks' approach to programming in R
library(dplyr)
library(rlang)
setwd(here("Scripts"))
# We essentially want to run Define_Interaction.R, but rather than simply using single stressor effects to predict growth
# We want to use the sum of all (component effects at (richness - 1) divided by richness)
# I'm not planning to use all component levels of richness to try and predict interactions, because life's too short
# Set your p-cutoff for additivism here
p_cutoff <- 0.05
# We'll need this vector for filtering component combinations later
temp_filter_vector <- vector(length = 8, mode = "character")
# Calculate the effect of individual stressors relative to controls, by isolate
emergent_interactions_tibble <- all_interactions_tibble %>%
mutate(pred_comp_mean = 0, pred_comp_sd = 0, pred_comp_n = 0, pred_comp_interaction = "")
# This is ugly.
emergent_interactions_tibble_app <-
emergent_interactions_tibble[0,] %>%
mutate(pred_comp_interaction = "")
# By isolate
for (i in 1:8)
{
for (o in 3:8)
{
# For a given higher-order (n > 2) mixture, filter the tibble down
temp_ho_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o) %>% # in retrospect Richness == o is not very human-friendly
filter(Isolate == isolates_vector[i])
# Also generate a tibble of n-1 order interactions
temp_component_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Richness == o-1) %>%
filter(Isolate == isolates_vector[i])
# Now let's work out way through the combinations
for (r in 1:nrow(temp_ho_emergent_interaction_tibble))
{
# loop across stressor presence/absence data. append the names of any absent stressors to a vector we'll be using for filtering
for (q in 1:8)
{
if (temp_ho_emergent_interaction_tibble[r,q] == 1)
{
temp_filter_vector[q] <- colnames(temp_ho_emergent_interaction_tibble[q])
}
}
# Now that we've got a vector of all the stressors we care about, we can use it to filter the Richness == (n-1) dataset
# Remove empty elements
temp_filter_vector <- temp_filter_vector[temp_filter_vector != ""]
# paste paste paste
temp_filter <- paste("(", paste(paste("(", temp_filter_vector, " == 1", ")", sep = ""), collapse = " | "), ")", sep = "")
# And give it a stupid name
component_emergent_filtered_interaction_tibble <- temp_component_emergent_interaction_tibble %>%
filter_(temp_filter)
# filter_() is technically deprecated; however I am practically unable to understand quasiquotation though, so here it stays
# an elegant function for a more civilized age
# At some point when we're done we'll need to empty this vector again
temp_filter_vector[1:8] <- ""
# We can now calculate a pred_comp_mean from the divided sum of our component obs_means, likewise for n and sd
temp_ho_emergent_interaction_tibble$pred_comp_mean[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_mean = (sum(obs_mean)/nrow(component_emergent_filtered_interaction_tibble))))
# I believe here the standard deviation should be the equal to the square root of the sum of (the squared component SDs) divided by the number of component combinations
temp_ho_emergent_interaction_tibble$pred_comp_sd[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_sd = sqrt(sum((obs_mean ^ 2)))/nrow(component_emergent_filtered_interaction_tibble)))
# And our new sample size is summed, divided by the number of component combinations, and rounded to the nearest whole number
temp_ho_emergent_interaction_tibble$pred_comp_n[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_n = round(sum(obs_n) / nrow(component_emergent_filtered_interaction_tibble))))
# And now we're gonna T-test observed effect vs component predicted effect
# I really need to come up with better names for these things.
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
# If m1 > m2, then additive_test[1] > 0
additive_test <- t.test2(temp_ho_emergent_interaction_tibble$pred_comp_mean[r], temp_ho_emergent_interaction_tibble$obs_mean[r],
temp_ho_emergent_interaction_tibble$pred_comp_sd[r], temp_ho_emergent_interaction_tibble$obs_sd[r],
temp_ho_emergent_interaction_tibble$pred_comp_n[r], temp_ho_emergent_interaction_tibble$obs_n[r])
# We also need to catch NaNs and NAs
# We'll just use simple definitions of synergy and antagonism here.
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Predicted"
} else if (additive_test[3] > 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Synergy"
} else if (additive_test[3] < 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Antagonism"
} else
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Classification Error"
}
# And append to emergent_interactions_tibble_app
emergent_interactions_tibble_app <- bind_rows(emergent_interactions_tibble_app, temp_ho_emergent_interaction_tibble[r,])
}
}
}
# Diagnostics.
ggplot(data = emergent_interactions_tibble_app, aes(x = Isolate, fill = pred_comp_interaction)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
# Modifies tidier_growth_data to create Piggott et al. interaction definitions for every combination of stressors by isolate
# Also converts presence/absence data into columns for S1, S2, S3, etc
# Requires a whole buncha stuff.
# TODO: Make.
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(growthcurver)
library(data.table)
library(viridis)
library(forcats)
setwd(here("Scripts"))
source("Code/Final_Pipeline/t.test2.R")
source("Code/Final_Pipeline/Function_Aggregate_Fun_Groups.R")
# Set your p-cutoff for additivism here
p_cutoff <- 0.05
# Calculate the effect of individual stressors relative to controls, by isolate
all_interactions_tibble <- tibble()
# A big single stressor tibble that we can use in other scripts
big_single_stressor_data <- tibble()
for (s in 1:8)
{
# Create a tibble of all measurements for our chosen isolate
isolate_tidier_growth_data <- tidier_growth_data %>%
select(Copper, Nickel, Chloramphenicol, Ampicillin, Metaldehyde, Atrazine, Tebuconazole, Azoxystrobin, Isolate, Mean, SD, Richness, n) %>%
filter(Isolate == isolates_vector[s])
# Calculate a baseline from controls
control_baseline <- isolate_tidier_growth_data %>%
filter(Richness == 0) %>%
select(Isolate, Mean, SD, n)
# A tibble of single stressors
single_stressor_growth_data <- isolate_tidier_growth_data %>%
filter(Richness == 1) %>%
mutate(mean_effect = Mean - control_baseline$Mean) %>%
mutate(sd_effect = sqrt((SD ^ 2) + (control_baseline$SD ^ 2))) %>% # New SD is the square root of the summed squared SDs
mutate(n_effect = n) %>%
mutate(Stressor = "")
# This breaks a lot currently as I don't always have a measurement for every single stressor/isolate combination
# Loop across the single stressor info to make sure they all get the right stressor assigned to the right effect
for (p in 1:nrow(single_stressor_growth_data))
{
for (q in 1:8)
{
if (single_stressor_growth_data[p,q] == 1)
{
single_stressor_growth_data$Stressor[p] <- colnames(single_stressor_growth_data[q])
}
}
}
# get rid of presence/absence columns
single_stressor_growth_data <- single_stressor_growth_data %>%
select(-Copper, -Nickel, -Chloramphenicol, -Ampicillin, -Metaldehyde, -Atrazine, -Tebuconazole, -Azoxystrobin, -Mean, -SD, -Richness, -n)
# This ugly boy here reorders the single stressor data to stressors_vector so I don't accidentally predict using the wrong data!
single_stressor_growth_data$Stressor <- factor(single_stressor_growth_data$Stressor, levels = stressors_vector)
single_stressor_growth_data <- single_stressor_growth_data[order(single_stressor_growth_data$Stressor),]
big_single_stressor_data <- bind_rows(big_single_stressor_data, single_stressor_growth_data)
# And all mixtures
mixture_tidier_growth_data <- isolate_tidier_growth_data %>%
filter(Richness > 1) %>%
mutate(obs_mean = Mean - control_baseline$Mean) %>%
mutate(obs_sd = sqrt((SD ** 2) + (control_baseline$SD ** 2))) %>%
mutate(obs_n = n) %>%
mutate(pred_mean = 0) %>%
mutate(pred_sd = 0) %>%
mutate(pred_n = 0) %>%
mutate(Interaction = "") %>%
select(-Mean, -SD, -n)
# For loop across all the mixtures
for (p in 1:nrow(mixture_tidier_growth_data))
{
mixture_counter <- 0
temp_stressors <- vector(mode = "numeric", length = 8)
for (q in 1:8)
{
if ((mixture_tidier_growth_data[p,q] == 1) && (mixture_counter < mixture_tidier_growth_data$Richness[p]))
{
# If a stressor is present, add the relevant means and sd from single_stressor_growth_data
# We're summming means here because we're calculating an additive effect
mixture_tidier_growth_data$pred_mean[p] <- mixture_tidier_growth_data$pred_mean[p] + single_stressor_growth_data$mean_effect[q]
mixture_tidier_growth_data$pred_sd[p] <- sqrt((mixture_tidier_growth_data$pred_sd[p] ^ 2) + (single_stressor_growth_data$sd_effect[q] ^ 2))
mixture_tidier_growth_data$pred_n[p] <- mixture_tidier_growth_data$pred_n[p] + single_stressor_growth_data$n_effect[q]
mixture_counter <- mixture_counter + 1
# And append the stressor effect to temp_stressors so we can calculate the regions of Piggott synergy and antagonism
temp_stressors[q] <- single_stressor_growth_data$mean_effect[q]
}
if (mixture_counter == mixture_tidier_growth_data$Richness[p])
{
# Once the additive mean and sd are calculated, we can compare the two to determine the interaction type. This is where it gets complicated.
# Divide the pred_n by richness and round it up
mixture_tidier_growth_data$pred_n[p] <- ceiling((mixture_tidier_growth_data$pred_n[p])/(mixture_tidier_growth_data$Richness[p]))
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
additive_test <- t.test2(mixture_tidier_growth_data$pred_mean[p], mixture_tidier_growth_data$obs_mean[p],
mixture_tidier_growth_data$pred_sd[p], mixture_tidier_growth_data$obs_sd[p],
mixture_tidier_growth_data$pred_n[p], mixture_tidier_growth_data$obs_n[p])
# We also need to catch NaNs and NAs
# Set some upper and lower bounds of synergies for cleaner code
upper_bound <- max(mixture_tidier_growth_data$pred_mean[p], temp_stressors, 0)
lower_bound <- min(mixture_tidier_growth_data$pred_mean[p], temp_stressors, 0)
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
mixture_tidier_growth_data$Interaction[p] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
mixture_tidier_growth_data$Interaction[p] <- "Additive"
} else if (mixture_tidier_growth_data$obs_mean[p] > upper_bound)
{
mixture_tidier_growth_data$Interaction[p] <- "+ Synergy"
} else if (mixture_tidier_growth_data$obs_mean[p] < lower_bound)
{
mixture_tidier_growth_data$Interaction[p] <- "- Synergy"
} else if (mixture_tidier_growth_data$obs_mean[p] < mixture_tidier_growth_data$pred_mean[p])
{
mixture_tidier_growth_data$Interaction[p] <- "- Antagonism"
} else if (mixture_tidier_growth_data$obs_mean[p] > mixture_tidier_growth_data$pred_mean[p])
{
mixture_tidier_growth_data$Interaction[p] <- "+ Antagonism"
} else
{
mixture_tidier_growth_data$Interaction[p] <- "Classification Error"
}
# This is crude, I think it works.
mixture_counter <- 0
}
}
}
all_interactions_tibble <- bind_rows(all_interactions_tibble, mixture_tidier_growth_data)
}
# Think of this as a diagnostic plot.
interaction_order <- c("+ Synergy", "- Antagonism", "Additive", "+ Antagonism", "- Synergy", "T-test error")
all_interactions_tibble$Interaction <- factor(all_interactions_tibble$Interaction, levels = interaction_order)
ggplot(data = all_interactions_tibble, aes(x = Isolate, fill = Interaction)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
# Diagnosis: a bad dataset.
meh <- ggplot(data = all_interactions_tibble, aes(x = pred_mean, y = obs_mean, colour = Interaction)) +
geom_point() +
scale_colour_viridis_d()
meh
ggplot(data = all_interactions_tibble, aes(x = Isolate, fill = Interaction)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
ggplot(data = all_interactions_tibble, aes(x = Isolate, fill = Interaction, width = Richness)) +
scale_colour_viridis_d(aesthetics = "fill", option = "viridis", direction = -1, drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste("p <", p_cutoff))
install.packages("scales")
install.packages("scales")
