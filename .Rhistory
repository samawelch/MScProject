Metaldehyde = temp_data_growth_0$Metaldehyde[[1]],
Atrazine = temp_data_growth_0$Atrazine[[1]],
Tebuconazole = temp_data_growth_0$Tebuconazole[[1]],
Azoxystrobin = temp_data_growth_0$Azoxystrobin[[1]],
Isolate = temp_data_growth_0$Isolate[[1]])
tidy_growth_data <- bind_rows(tidy_growth_data, temp_data_growth_2)
}
#
#
#   # Delete bad fits for the well if we now have a good one
#   tidy_growth_data <- tidy_growth_data %>%
#     filter(((location != temp_data_growth_0$location[[1]]) && (temp_data_growth_1$vals$note != "")))
# append the area under the empirical curve (auc_e, etc. to tidy_growth_data)
# count bad fits
if (temp_data_growth_1$vals$note != "")
{
bad_fit_count = bad_fit_count + 1
}
# Cannabalised for loop to generate a text string of stressors present, to annotate growth curve printouts. Ugly and fragile.
# for (q in 4:11)
# {
#   if (temp_data_growth_0[1,q] == 1)
#   {
#     # If a stressor is present, append it to the cell name
#     temp_well_stressor_list <- paste(temp_well_stressor_list,abbreviate(colnames(temp_data_growth_0[q]), minlength = 2), sep = "")
#   }
# }
# # we can also generate plate curve graphics:
# temp_data_growth_4 <- as.tibble(temp_data_growth_1$data)
# # TODO: Fix this horrible if statement.
# if (is.character(temp_data_growth_1$model) == FALSE)
#   # Apparently if growthcurver can't fit a curve it returns a character instead. This is hardly helpful. So we need an if/else statement to catch these.
# {
#   temp_predict <- data.frame(time = temp_data_growth_0$time, pred.wt = predict(temp_data_growth_1$model, sigma = temp_data_growth_1$model$sigma))
#
#   # Render a temporary plot of the data points and the logistic curve from growthcurver (stored in temp_predict)
#   temp_plot <- ggplot(temp_data_growth_0, aes(x = time, y = OD)) +
#     geom_point() +
#     geom_line(data = temp_predict, aes(x = time, y = pred.wt), colour = "deepskyblue1") +
#     ggtitle(temp_data_growth_2$location) +
#     theme(axis.title.x=element_blank(),
#           axis.ticks.x=element_blank(),
#           axis.title.y=element_blank(),
#           axis.ticks.y=element_blank()) +
#     ylim(0,1) +
#     annotate("text", x = 10, y = 0.5, label = temp_well_stressor_list, colour = "deepskyblue1") +
#     annotate("text", x = 10, y = 0.7, label = temp_data_growth_1$vals$note, colour = "deepskyblue1") +
#     annotate("text", x = 10, y = 0.3, label = temp_data_growth_2$Run, colour = "deepskyblue1")
# }
# else
# {
#   temp_plot <- ggplot(temp_data_growth_0, aes(x = time, y = OD)) +
#     geom_point() +
#     ggtitle(temp_data_growth_2$location) +
#     theme(axis.title.x=element_blank(),
#           axis.ticks.x=element_blank(),
#           axis.title.y=element_blank(),
#           axis.ticks.y=element_blank()) +
#     ylim(0,1) +
#     annotate("text", x = 25, y = 0.5, label = temp_well_stressor_list, colour = "deepskyblue1") +
#     annotate("text", x = 10, y = 0.3, label = temp_data_growth_2$Run, colour = "deepskyblue1")
# }
#
# temp_plot_name <- paste("well_curve", temp_data_growth_2$location, "Run", run_count ,sep = "_")
# assign(temp_plot_name, temp_plot)
# well_curve_plot_vector[[l]] <- temp_plot
# temp_well_stressor_list <- "" # Don't forget to clear it here...
}
# Loop #2
timepoints_count <- 10 # the issue is by setting timepoints here we start our second for loop (3 * 6433) positions earlier than we should...
for (l in 1:2144)
{
temp_data_growth_0 <-
tidy_data[((l-1) * timepoints_count + 83617) : ((l * timepoints_count) + 83616), ] %>%     # Turn every timepoints_count measurements into a single df
filter(time <= time_cutoff)
temp_data_growth_1 <- SummarizeGrowth(temp_data_growth_0$time, temp_data_growth_0$OD)        # Generate a logistic model for this well's growth
# If it's a good fit, it goes in. This is going to break a lot of interaction calculations for the time being.
if (temp_data_growth_1$vals$note == "")
{
temp_data_growth_2 <- bind_cols(location = temp_data_growth_0$location[[1]],
Run = temp_data_growth_0$Run[[1]],
Growth_auc_e = temp_data_growth_1$vals$auc_e,
Growth_auc_l = temp_data_growth_1$vals$auc_l,
Growth_k = temp_data_growth_1$vals$k, # TODO: Change coordinates to colnames.
Growth_r = temp_data_growth_1$vals$r,
Growth_n0 = temp_data_growth_1$vals$n0,
Growth_sigma = temp_data_growth_1$vals$sigma,
Fit_notes = temp_data_growth_1$vals$note,
Max_Growth = max(temp_data_growth_0$OD),
Copper = temp_data_growth_0$Copper[[1]],
Nickel = temp_data_growth_0$Nickel[[1]],
Chloramphenicol = temp_data_growth_0$Chloramphenicol[[1]],
Ampicillin = temp_data_growth_0$Ampicillin[[1]],
Metaldehyde = temp_data_growth_0$Metaldehyde[[1]],
Atrazine = temp_data_growth_0$Atrazine[[1]],
Tebuconazole = temp_data_growth_0$Tebuconazole[[1]],
Azoxystrobin = temp_data_growth_0$Azoxystrobin[[1]],
Isolate = temp_data_growth_0$Isolate[[1]])
tidy_growth_data <- bind_rows(tidy_growth_data, temp_data_growth_2)
}
if (temp_data_growth_1$vals$note != "")
{
bad_fit_count = bad_fit_count + 1
}
}
# Just to give an idea of how good the fits are...
cat("bad fits: \n", bad_fit_count, "\n")
cat("of total wells: \n", wells_count, "\n")
# This is broken now that there are different numbers of timepoint per well
# Take tidy_growth_data from Growth_Curve_Loop and get cracking on some means and standard deviations
# TODO: Be really, really sure about the difference between SE and SD and which is more appropriate to use here
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(growthcurver)
library(gridBase)
library(gridExtra)
setwd(here("Scripts"))
#######################
### SET INPUTS HERE ###
#######################
# Pick a growth metric. This will be used in all dependent scripts, so choose carefully...
growth_metric <- "Growth_auc_e"
# (UQ(rlang::sym(growth_metric))) notation is used to cleanly insert your chosen growth metric into data manipulation functions
#######################
##### Main Script #####
#######################
# Make a new tibble with a clever name. And a measure of stressor richness.
tidier_growth_data <-
tidy_growth_data %>%
select(location, Growth_auc_e, Growth_auc_l, Growth_k, Growth_r, Growth_n0, Growth_sigma, Max_Growth, Fit_notes, Copper, Nickel, Chloramphenicol, Ampicillin, Atrazine, Metaldehyde, Tebuconazole, Azoxystrobin, Isolate) %>%
mutate(Complexity = Copper + Nickel + Chloramphenicol + Ampicillin + Atrazine + Metaldehyde + Tebuconazole + Azoxystrobin)
# Pull out our controls so we can average them by Isolate rather than location
temp_control_means <- tidier_growth_data %>%
filter(Complexity == 0) %>%
select(-location) %>%
group_by(Isolate) %>%
mutate(Mean = mean(UQ(rlang::sym(growth_metric)))) %>%
mutate(SD = sd(UQ(rlang::sym(growth_metric)))) %>%
mutate(n = n()) %>%
select(-Growth_auc_e, -Growth_auc_l, -Growth_k, -Growth_r, -Growth_n0, -Growth_sigma, -Fit_notes, -Max_Growth) %>%
distinct() %>% # TODO:  I still don't know a better way to average across rows in one fell swoop
ungroup()
# Average the remaining treatment wells by location
tidier_growth_data <- tidier_growth_data %>%
mutate(Complexity = Copper + Nickel + Chloramphenicol + Ampicillin + Atrazine + Metaldehyde + Tebuconazole + Azoxystrobin) %>%
filter(Complexity != 0) %>%
group_by(location) %>%
mutate(Mean = mean(UQ(rlang::sym(growth_metric)))) %>%
mutate(SD = sd(UQ(rlang::sym(growth_metric)))) %>%
mutate(n = n()) %>%
select(-Growth_auc_e, -Growth_auc_l, -Growth_k, -Growth_r, -Growth_n0, -Growth_sigma, -Fit_notes, -Max_Growth) %>%
distinct() %>%
ungroup() %>%
select(-location)
# And merge them back together! Which now that I come to think of it may not be necessary?
tidier_growth_data <- bind_rows(tidier_growth_data, temp_control_means)
# How many problems are we likely to have with poor replication (spoiler: lots)
paste("bad wells", nrow(filter(tidier_growth_data, n == 1)))
paste("total wells", nrow(tidier_growth_data))
# Calculate sample size range for each isolate
sample_size <- tidier_growth_data %>%
group_by(Isolate) %>%
summarise(Mean_n = mean(n), SD_n = sd(n))
write.csv(sample_size, "Results/Final_Pipeline/sample_sizes_table.csv")
# Modifies tidier_growth_data to create Piggott et al. interaction definitions for every combination of stressors by isolate
# Also converts presence/absence data into columns for S1, S2, S3, etc
# Requires a whole buncha stuff.
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(growthcurver)
library(data.table)
library(viridis)
library(forcats) # sadly nothing to do with cats
library(ggpubr)
library(here)
setwd(here("Scripts"))
source("Code/Final_Pipeline/t.test2.R")
source("Code/Final_Pipeline/Function_Aggregate_Fun_Groups.R")
# Set your p-cutoff for additivism here
p_cutoff <- 0.05
# Calculate the effect of individual stressors relative to controls, by isolate
all_interactions_tibble <- tibble()
# A big single stressor tibble that we can use in other scripts
big_single_stressor_data <- tibble()
for (s in 1:8)
{
# Create a tibble of all measurements for our chosen isolate
isolate_tidier_growth_data <- tidier_growth_data %>%
select(Copper, Nickel, Chloramphenicol, Ampicillin, Metaldehyde, Atrazine, Tebuconazole, Azoxystrobin, Isolate, Mean, SD, Complexity, n) %>%
filter(Isolate == isolates_vector[s])
# Calculate a baseline from controls
control_baseline <- isolate_tidier_growth_data %>%
filter(Complexity == 0) %>%
select(Isolate, Mean, SD, n)
# A tibble of single stressors
single_stressor_growth_data <- isolate_tidier_growth_data %>%
filter(Complexity == 1) %>%
mutate(mean_effect = Mean - control_baseline$Mean) %>%
mutate(sd_effect = sqrt((SD ^ 2) + (control_baseline$SD ^ 2))) %>% # New SD is the square root of the summed squared SDs
mutate(n_effect = n) %>%
mutate(Stressor = "")
# This breaks a lot currently as I don't always have a measurement for every single stressor/isolate combination
# Loop across the single stressor info to make sure they all get the right stressor assigned to the right effect
for (p in 1:nrow(single_stressor_growth_data))
{
for (q in 1:8)
{
if (single_stressor_growth_data[p,q] == 1)
{
single_stressor_growth_data$Stressor[p] <- colnames(single_stressor_growth_data[q])
}
}
}
# get rid of presence/absence columns
single_stressor_growth_data <- single_stressor_growth_data %>%
select(-Copper, -Nickel, -Chloramphenicol, -Ampicillin, -Metaldehyde, -Atrazine, -Tebuconazole, -Azoxystrobin, -Mean, -SD, -Complexity, -n)
# This ugly boy here reorders the single stressor data to stressors_vector so I don't accidentally predict using the wrong data!
single_stressor_growth_data$Stressor <- factor(single_stressor_growth_data$Stressor, levels = stressors_vector)
single_stressor_growth_data <- single_stressor_growth_data[order(single_stressor_growth_data$Stressor),]
big_single_stressor_data <- bind_rows(big_single_stressor_data, single_stressor_growth_data)
# And all mixtures
mixture_tidier_growth_data <- isolate_tidier_growth_data %>%
filter(Complexity > 1) %>%
mutate(obs_mean = Mean - control_baseline$Mean) %>%
mutate(obs_sd = sqrt((SD ** 2) + (control_baseline$SD ** 2))) %>%
mutate(obs_n = n) %>%
mutate(pred_mean = 0) %>%
mutate(pred_sd = 0) %>%
mutate(pred_n = 0) %>%
mutate(Interaction = "") %>%
select(-Mean, -SD, -n)
# For loop across all the mixtures
for (p in 1:nrow(mixture_tidier_growth_data))
{
mixture_counter <- 0
temp_stressors <- vector(mode = "numeric", length = 8)
for (q in 1:8)
{
if ((mixture_tidier_growth_data[p,q] == 1) && (mixture_counter < mixture_tidier_growth_data$Complexity[p]))
{
# If a stressor is present, add the relevant means and sd from single_stressor_growth_data
# We're summming means here because we're calculating an additive effect
mixture_tidier_growth_data$pred_mean[p] <- mixture_tidier_growth_data$pred_mean[p] + single_stressor_growth_data$mean_effect[q]
mixture_tidier_growth_data$pred_sd[p] <- sqrt((mixture_tidier_growth_data$pred_sd[p] ^ 2) + (single_stressor_growth_data$sd_effect[q] ^ 2))
mixture_tidier_growth_data$pred_n[p] <- mixture_tidier_growth_data$pred_n[p] + single_stressor_growth_data$n_effect[q]
mixture_counter <- mixture_counter + 1
# And append the stressor effect to temp_stressors so we can calculate the regions of Piggott synergy and antagonism
temp_stressors[q] <- single_stressor_growth_data$mean_effect[q]
}
if (mixture_counter == mixture_tidier_growth_data$Complexity[p])
{
# Once the additive mean and sd are calculated, we can compare the two to determine the interaction type. This is where it gets complicated.
# Divide the pred_n by richness and round it up
mixture_tidier_growth_data$pred_n[p] <- ceiling((mixture_tidier_growth_data$pred_n[p])/(mixture_tidier_growth_data$Complexity[p]))
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
additive_test <- t.test2(mixture_tidier_growth_data$pred_mean[p], mixture_tidier_growth_data$obs_mean[p],
mixture_tidier_growth_data$pred_sd[p], mixture_tidier_growth_data$obs_sd[p],
mixture_tidier_growth_data$pred_n[p], mixture_tidier_growth_data$obs_n[p])
# We also need to catch NaNs and NAs
# Set some upper and lower bounds of synergies for cleaner code
upper_bound <- max(mixture_tidier_growth_data$pred_mean[p], temp_stressors, 0)
lower_bound <- min(mixture_tidier_growth_data$pred_mean[p], temp_stressors, 0)
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
mixture_tidier_growth_data$Interaction[p] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
mixture_tidier_growth_data$Interaction[p] <- "Additive"
} else if (mixture_tidier_growth_data$obs_mean[p] > upper_bound)
{
mixture_tidier_growth_data$Interaction[p] <- "+ Synergy"
} else if (mixture_tidier_growth_data$obs_mean[p] < lower_bound)
{
mixture_tidier_growth_data$Interaction[p] <- "- Synergy"
} else if (mixture_tidier_growth_data$obs_mean[p] < mixture_tidier_growth_data$pred_mean[p])
{
mixture_tidier_growth_data$Interaction[p] <- "- Antagonism"
} else if (mixture_tidier_growth_data$obs_mean[p] > mixture_tidier_growth_data$pred_mean[p])
{
mixture_tidier_growth_data$Interaction[p] <- "+ Antagonism"
} else
{
mixture_tidier_growth_data$Interaction[p] <- "Classification Error"
}
# This is crude, I think it works.
mixture_counter <- 0
}
}
}
all_interactions_tibble <- bind_rows(all_interactions_tibble, mixture_tidier_growth_data)
# Plot a rather ugly bar chart of interactions by richness, by isolate
interaction_order <- c("+ Synergy", "- Antagonism", "Additive", "+ Antagonism", "- Synergy", "T-test error")
all_interactions_tibble$Interaction <- factor(all_interactions_tibble$Interaction, levels = interaction_order)
temp_plot <-
ggplot(data = filter(all_interactions_tibble, Isolate == isolates_vector[s]),
aes(x = as.factor(Complexity),
fill = Interaction,
width = 0.9)) +
scale_colour_viridis_d(aesthetics = "fill",
option = "viridis",
direction = -1,
drop = FALSE) +
geom_bar(position = "stack") +
ggtitle(paste(isolates_species_vector[s])) +
theme_gray() +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major.x = element_blank())
temp_plot_name <- paste("p", s , sep = "")
assign(temp_plot_name, temp_plot)
}
dummy_legend <- get_legend(
temp_plot +
theme(legend.position = "right",
legend.key.size = unit(1.1, "cm"))
)
setwd(here("Scripts"))
pdf("Results/Final_Pipeline/histogram_interaction_basic.pdf", width = 9, height = 9)
annotate_figure(ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, dummy_legend),
left = text_grob("Interaction Count", rot = 90),
bottom = text_grob("Mixture Complexity"))
dev.off()
dev.off()
annotate_figure(ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, dummy_legend),
left = text_grob("Interaction Count", rot = 90),
bottom = text_grob("Mixture Complexity"))
# A test for emergent interactions, using Beppler's measurement of bacterial fitness to predict complex interactions from component interactions
# The magnum opus of my 'throw a lot of for loops at a wall and see what sticks' approach to programming in R
library(dplyr)
library(rlang)
library(here)
setwd(here("Scripts"))
# We essentially want to run Define_Interaction.R, but rather than simply using single stressor effects to predict growth
# We want to use the sum of all (component effects at (richness - 1) divided by richness)
# I'm not planning to use all component levels of richness to try and predict interactions, because life's too short
# Set your p-cutoff for additivism here
p_cutoff <- 0.05
# We'll need this vector for filtering component combinations later
temp_filter_vector <- vector(length = 8, mode = "character")
# Calculate the effect of individual stressors relative to controls, by isolate
emergent_interactions_tibble <- all_interactions_tibble %>%
mutate(pred_comp_mean = 0, pred_comp_sd = 0, pred_comp_n = 0, pred_comp_interaction = "")
# This is ugly.
emergent_interactions_tibble_app <-
emergent_interactions_tibble[0,] %>%
mutate(pred_comp_interaction = "")
# By isolate
for (i in 1:8)
{
for (o in 3:8)
{
# For a given higher-order (n > 2) mixture, filter the tibble down
temp_ho_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Complexity == o) %>% # in retrospect Complexity == o is not very human-friendly
filter(Isolate == isolates_vector[i])
# Also generate a tibble of n-1 order interactions
temp_component_emergent_interaction_tibble <- emergent_interactions_tibble %>%
filter(Complexity == o-1) %>%
filter(Isolate == isolates_vector[i])
# Now let's work out way through the combinations
for (r in 1:nrow(temp_ho_emergent_interaction_tibble))
{
# loop across stressor presence/absence data. append the names of any absent stressors to a vector we'll be using for filtering
for (q in 1:8)
{
if (temp_ho_emergent_interaction_tibble[r,q] == 1)
{
temp_filter_vector[q] <- colnames(temp_ho_emergent_interaction_tibble[q])
}
}
# Now that we've got a vector of all the stressors we care about, we can use it to filter the Complexity == (n-1) dataset
# Remove empty elements
temp_filter_vector <- temp_filter_vector[temp_filter_vector != ""]
# paste paste paste
temp_filter <- paste("(", paste(paste("(", temp_filter_vector, " == 1", ")", sep = ""), collapse = " | "), ")", sep = "")
# And give it a stupid name
component_emergent_filtered_interaction_tibble <- temp_component_emergent_interaction_tibble %>%
filter_(temp_filter)
# filter_() is technically deprecated; however I am practically unable to understand quasiquotation though, so here it stays
# an elegant function for a more civilized age
# At some point when we're done we'll need to empty this vector again
temp_filter_vector[1:8] <- ""
# We can now calculate a pred_comp_mean from the divided sum of our component obs_means, likewise for n and sd
temp_ho_emergent_interaction_tibble$pred_comp_mean[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_mean = (sum(obs_mean)/nrow(component_emergent_filtered_interaction_tibble))))
# I believe here the standard deviation should be the equal to the square root of the sum of (the squared component SDs) divided by the number of component combinations
temp_ho_emergent_interaction_tibble$pred_comp_sd[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_sd = sqrt(sum((obs_mean ^ 2)))/nrow(component_emergent_filtered_interaction_tibble)))
# And our new sample size is summed, divided by the number of component combinations, and rounded to the nearest whole number
temp_ho_emergent_interaction_tibble$pred_comp_n[r] <-
as.numeric(summarize(component_emergent_filtered_interaction_tibble,
adjusted_n = round(sum(obs_n) / nrow(component_emergent_filtered_interaction_tibble))))
# And now we're gonna T-test observed effect vs component predicted effect
# I really need to come up with better names for these things.
# Now we need to t-test the observed vs predicted effect. We'll be rejecting the null hypothesis for p < 0.05
# If m1 > m2, then additive_test[1] > 0
additive_test <- t.test2(temp_ho_emergent_interaction_tibble$pred_comp_mean[r], temp_ho_emergent_interaction_tibble$obs_mean[r],
temp_ho_emergent_interaction_tibble$pred_comp_sd[r], temp_ho_emergent_interaction_tibble$obs_sd[r],
temp_ho_emergent_interaction_tibble$pred_comp_n[r], temp_ho_emergent_interaction_tibble$obs_n[r])
# We also need to catch NaNs and NAs
# We'll just use simple definitions of synergy and antagonism here.
if (is.na(additive_test[4]) || is.nan(additive_test[4]))
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "T-test error"
} else if (additive_test[4] >= p_cutoff)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Predicted"
} else if (additive_test[1] < 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Synergy"
} else if (additive_test[1] > 0)
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Emergent Antagonism"
} else
{
temp_ho_emergent_interaction_tibble$pred_comp_interaction[r] <- "Classification Error"
}
# And append to emergent_interactions_tibble_app
emergent_interactions_tibble_app <- bind_rows(emergent_interactions_tibble_app, temp_ho_emergent_interaction_tibble[r,])
}
}
# Plot time!
interaction_order <- c("Emergent Synergy", "Predicted", "Emergent Antagonism", "T-test error")
emergent_interactions_tibble_app$pred_comp_interaction <- factor(emergent_interactions_tibble_app$pred_comp_interaction, levels = interaction_order)
temp_plot <-
ggplot(data = filter(emergent_interactions_tibble_app, Isolate == isolates_vector[i]),
aes(x = as.factor(Complexity),
fill = pred_comp_interaction),
width = 0.9) +
scale_colour_viridis_d(aesthetics = "fill",
option = "viridis",
direction = -1,
drop = FALSE,
begin = 0,
end = 1) +
geom_bar(position = "stack") +
ggtitle(paste(isolates_species_vector[i])) +
theme_gray() +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major.x = element_blank())
temp_plot_name <- paste("p", i , sep = "")
assign(temp_plot_name, temp_plot)
}
dummy_legend <- get_legend(
temp_plot +
theme(legend.position = "right",
legend.key.size = unit(1.1, "cm")) +
labs(fill = 'Emergent Interaction')
)
pdf("Results/Final_Pipeline/histogram_interaction_emergent.pdf", width = 9, height = 9)
annotate_figure(ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, dummy_legend),
left = text_grob("Interaction Count", rot = 90),
bottom = text_grob("Mixture Complexity"))
dev.off()
dev.off()
annotate_figure(ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, dummy_legend),
left = text_grob("Interaction Count", rot = 90),
bottom = text_grob("Mixture Complexity"))
# Plot all_interactions_tibble's observed effects against predicted effects.
# Requires a lot of stuff - but most importantly Define_Interactions.R
# Includes viridis for colourblind-friendly (and prettier) colour gradients
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(growthcurver)
library(gridBase)
library(gridExtra)
library(ggpubr)
library(viridis)
library(here)
setwd(here("Scripts"))
# For loop through 2-7 way interactions and graph them out
for (i in 1:8)
{
interactions_temp <- filter(all_interactions_tibble, Isolate == isolates_vector[i])
plot_i_temp <- ggplot(interactions_temp, aes(x = pred_mean, y = obs_mean)) +
geom_point(aes(colour = Complexity), size = 2, alpha = 0.9, shape = 16) +
scale_colour_viridis(discrete = FALSE) +
theme(legend.position="none") +
geom_abline(slope = 1, intercept = 0, colour = "grey", size = 1) +
ggtitle(isolates_species_vector[i]) +
# Consistent scaling isn't great...
scale_x_continuous(limits = c(-15, 15)) +
scale_y_continuous(limits = c(-6, 6)) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank()) +
annotate("text", x = -12.5, y = 6, label = "Synergy", colour = "darkgrey") +
annotate("text", x = 11.25, y = -6, label = "Antagonism", colour = "darkgrey")
temp_plot_name <- paste("p", i , sep = "")
assign(temp_plot_name, plot_i_temp)
}
dummy_legend <- get_legend(p1 + theme(legend.position="right", legend.key.size = unit(1.1, "cm")))
# Plot together, aligned by species
pdf("Results/Final_Pipeline/ObservedXPredicted.pdf", width = 9, height = 9)
annotate_figure(ggarrange(p2, p4, p1, p7, p6, p5, p3, p8, dummy_legend, ncol = 3, nrow = 3),
bottom = text_grob("Mean Predicted Additive Area under Growth Curve"),
left = text_grob("Mean Observed Area under Growth Curve", rot = 90))
dev.off()
annotate_figure(ggarrange(p2, p4, p1, p7, p6, p5, p3, p8, dummy_legend, ncol = 3, nrow = 3),
bottom = text_grob("Mean Predicted Additive Area under Growth Curve"),
left = text_grob("Mean Observed Area under Growth Curve", rot = 90))
