setwd(here("Scripts")) # Hopefully a slighly more rational way to handle WDs. Run here() for project directory.
library(here)
setwd(here("Scripts")) # Hopefully a slighly more rational way to handle WDs. Run here() for project directory.
\documentclass{article}
\begin{document}
\SweaveOpts{concordance=TRUE}
\title{1. Mixtures and Microbes}
\author{Sam Welch}
\begin{document}
\maketitle
Every organism sits at the heart of a complex and changing web of ecological pressures, and as long as there has been life, life has been shaped by these interdependent and interacting stressors, biotic and abiotic. Though humans are arguably not the first species to trigger a lethal global pollution crisis (Blaustein, 2016), the sheer variety of anthropogenic chemicals that enter the environment today represents a growing and unpredictable threat to the health of humanity, ecosystems, and the planet.
\end{document}
\ documentclass [ a4paper ]{ article }
\ title { Sweave Example 1}
\ author { Friedrich Leisch }
\ usepackage { Sweave }
\ begin { document }
\ maketitle
In this example we embed parts of the examples from the
\ texttt { kruskal . test } help page into a \ LaTeX {} document :
\ begin { Schunk }
\ begin { Sinput }
> data ( airquality , package =" datasets ")
> library (" stats ")
> kruskal . test ( Ozone ~ Month , data = airquality )
\ end { Sinput }
\ begin { Soutput }
Kruskal - Wallis rank sum test
data : Ozone by Month
Kruskal - Wallis chi - squared = 29.267 , df = 4 , p - value = 6.901 e -06
\ end { Soutput }
\ end { Schunk }
which shows that the location parameter of the Ozone
distribution varies significantly from month to month . Finally , we
include a boxplot of the data , using
%% want an eval = FALSE case and referencing a previous chunk :
\ begin { Schunk }
\ begin { Sinput }
> boxplot ( Ozone ~ Month , data = airquality )
\ end { Sinput }
\ end { Schunk }
\ begin { center }
\ includegraphics { example -1 -003}
\ end { center }
\ end { document }
\documentclass{article}
\usepackage{biblatex}
\addbibresource{Project-Used_Citations.bib}
\begin{document}
\SweaveOpts{concordance=TRUE}
Every organism sits at the heart of a complex and changing web of ecological pressures, and as long as there has been life, life has been shaped by these interdependent and interacting stressors, biotic and abiotic. Though humans are arguably not the first species to trigger a lethal global pollution crisis \cite{Blaustein2016}, the sheer variety of anthropogenic chemicals that enter the environment today represents a growing and unpredictable threat to the health of humanity, ecosystems, and the planet.
\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{biblatex}
\addbibresource{sample.bib}
# Loads modified Synergy 2 well data as CSVs from Run_X folders. Compiles into a tidy dataset of OD by time, well, stressor presence/absence and isolate.
# Also implements a number of counters needed by future for loops. Can (theoretically) handle as many replicates as needed.
library(dplyr)
library(tidyverse)
library(ggplot2)
library(growthcurver)
library(gridBase)
library(gridExtra)
library(here)
setwd(here("Scripts")) # Hopefully a slighly more rational way to handle WDs. Run here() for project directory.
# See https://www.rdocumentation.org/packages/here/versions/0.1 for here package documentations.
#Start from a tabula rasa
rm(list=ls())
#######################
### SET INPUTS HERE ###
#######################
# How many timepoints does your data have?
read_timepoints <- 49
# This is no longer usable for a bncuh of stuff because runs 4 & 5 only read every 4 hours
# Every how many hours do we want to take a reading?
read_rate <- 4
# How many runs are you importing? (Run importing will start from 2 as run 1 was a write-off)
run_count <- 2
# Load in the plate layout csv for combination and isolate location data
plate_layout <- read.csv("Data/Final_Pipeline/256comb_8bact_plate.csv") %>%
unite(loc, Dest.Row, Dest.Column, sep = "") %>%
unite(location, loc, plate, sep = ".")
#######################
# Misc counters:
# How many plates are there?
plate_count = 0
# How many of the growth curves are bad or questionable fits?
bad_fit_count = 0
# Make a vector of isolates
isolates_vector <- as.vector(unique(plate_layout$Isolate))
isolates_species_vector <- c("KUE4_10 - S. acidaminiphila", "NUE1_1 - B. muralis", "LUF4_5 - L. rhizovicinus", "NUF1_3 - V. paradoxus", "KUB5_13 - V. paradoxus", "KUE4_4 - B. muralis", "E. coli OP50", "Nash's Field Soil Community")
# Make a vector of stressors
stressors_vector <- as.vector(colnames(plate_layout[1:8]))
stressors_vector_short <- abbreviate(stressors_vector, minlength = 2)
# And a colour vector for consistent colouring
stressor_colours <- c("Copper" = "red3", "Nickel" = "firebrick", "Chloramphenicol" = "plum", "Ampicillin" = "plum4", "Atrazine" = "darkgreen", "Metaldehyde" = "forestgreen", "Tebuconazole" = "steelblue", "Azoxystrobin" = "lightblue3", "None" = "black")
# Load in plate .CSVs from a seperate folder using a for loop. Make a tibble to contain the data.
setwd("C:/Users/Sam Welch/Google Drive/ICL Ecological Applications/Project/Work/Scripts/Data/Final_Pipeline/Run_2/csvs")
# Make sure your plates are correctly ordered in the wd. You will need leading 0s on your plate numbers for the below loop to read them in order.
tidy_data <- tibble()
#######################
##### Main Script #####
#######################
load_run_data <- function(run_number)
{
# run_number is just the run number, as an integer. Your run folders should be in the format "Run_X", with the .csvs in a nested folder "csvs"
setwd(here("Scripts", "Data", "Final_Pipeline", paste("Run_", run_number, sep = ""), "csvs"))
for (k in 1:length(dir()))
{
# Make a df for each plate with a numbered name & pad plate names with leading 0s so R orders them properly
temp_plate_name <- paste("plate", str_pad(k, 2, pad = "0") ,sep = "_")
temp_plate_df <- read.csv(dir()[k])
# fix a pesky capitalisation mismatch
colnames(temp_plate_df)[1] <- "time"
# turn the reader's odd time format in to something useful
temp_plate_df$time <- as.numeric(substr(temp_plate_df$time, 1, 2))
# turn the reader's odd time format in to something useful
# trim down each well to the number of time points set in read_timepoints
temp_plate_df <- filter(temp_plate_df, time <= read_timepoints)
temp_plate_width <- 97
# we need to remove the last 32 wells from every third plate. This is complicated because it's rows 9,10,11 & 12...
if ((k %% 3) == 0)
{
temp_plate_df <- temp_plate_df %>%
select(-contains("9")) %>%
select(-contains("10")) %>%
select(-contains("11")) %>%
select(-contains("12"))
temp_plate_width <- 65 # if it's a third plate it'll have 64 wells (and thus 65 columns including time)
}
assign(temp_plate_name, temp_plate_df)                         # turn our temporary df into a real df with a for-loop-generated name
# let's also make a massive tidy dataset that's better able to store stressor presence/absence and isolate species
temp_plate_tidy <- as.tibble(temp_plate_df) %>%
gather(well, OD, 2:temp_plate_width) %>%                       # gather the data from wide to tall
mutate(plate = k) %>%                            # add a plate column based on where we are in the for loop
unite(location, well, plate, sep = ".") %>%      # bring the location naming scheme in line with plate_layout
mutate(Run = run_number)
tidy_data <<- bind_rows(tidy_data, temp_plate_tidy)       # add the temporary data to our massive dataset (global assign as we're now in a function)
plate_count <<- plate_count + 1
}
}
# Load run data per run and append it to tidy_data. Starts at 2, because Run 1 was a write-off.
for (r in 2:(run_count + 1))
{
load_run_data(r)
}
setwd("C:/Users/Sam Welch/Google Drive/ICL Ecological Applications/Project/Work/Scripts")
# Join isolate/stressor data to growth data by observations
tidy_data <- left_join(tidy_data, plate_layout, by = "location")
# If we filter reads down to every 4 hours here we can save some thinking in Growth_Curve_Loop.R
tidy_data <- tidy_data %>%
filter((time %% read_rate) == 0)
# Now:
timepoints_count <- 13
# A few checks
glimpse(tidy_data)
# How many time points do we have?
timepoints_count <- length(unique(tidy_data$time))  # should be 49
timepoints_count
# How many wells do we have?
wells_count <- nrow(tidy_data) / timepoints_count # run count * 2144
wells_count
# How many plates
plate_count
# TODO: Intermediate output .csvs
